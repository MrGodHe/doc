# 背景

​	在现代计算机系统中，CPU（处理器），RAM（内存），DISK（硬盘）的速度不相同。CPU与RAM之间，RAM与DISK之间的速度差异常常是指数级。为了在速度和容量上折中，在CPU与RAM之间使用CPU cache以提高访存速度，在RAM与磁盘之间，操作系统使用page cache提高系统对文件的访问速度

​	操作系统处理文件主要问题：

​	1、相对于内存的高速读写，缓慢的硬盘驱动器，特别是磁盘寻道较为耗时。

​	2、文件加载到物理内存，并在多个程序间共享。

# **操作系统使用page cache机制读取文件流程：**

1. 应用程序请求获取512字节scene.dat文件的内容，使用系统调用 read(scene.dat, to_heap_buf, 512, offset=0)
2. 内核从页面缓存（page cache）中搜索满足请求的scene.dat文件的4KB的块，如果数据尚未缓存，则进入下一步
3. 内核申请页帧空间，进行I/O操作，从偏移位置0开始请求4KB的数据，并复制到页帧中。（**文件复制到内核内存空间中**）
4. 内核从page cache中复制512字节的数据到应用程序的缓存中，read()系统调用结束。（**文件从内核内存空间复制到应用程序内存空间**）

对于系统的所有文件I/O请求，操作系统都是通过page cache机制实现的，对于操作系统而言，磁盘文件都是由一系列的数据块顺序组成，数据块的大小随系统的不同而不同，x86 linux系统下是4KB（一个标准的页面大小）。内核在处理文件I/O请求时，首先到page cache中查找（page cache中的每一个数据块都设置了文件以及偏移信息），如果未命中，则启动磁盘I/O，将磁盘文件中的数据块加载到page cache中的一个空闲块，之后copy到用户缓冲区中。

**问题：**

​	在内存中保存了两份，这既占用了不必要的内存空间。

**Linux在使用mmap调用时：**

​	系统并不马上为其分配内存空间，而仅仅是添加一个VMA(Virtual Memory Area)到该进程中，当程序访问到目标空间时，产生缺页中断。在缺页中断中，从page cache中查找要访问的文件块，若未命中，则启动磁盘I/O从磁盘中加载到page cache，然后将文件块在page cache中的物理页映射到进程mmap地址空间。

​	当程序退出或关闭文件时，系统是否会马上清除page cache中的相应页面呢？答案是否定的。由于该文件可能被其它进程访问，或该进程一段时间后会重新访问，因此，在物理内存足够的情况下，系统总是将其保存在page cache中，这样可以提高系统的整体性能。只有当系统物理内存不足时，内核才会主动清理page cache。

​	当进程调用write修改文件时，由于page cache的存在，修改并不会马上更新到磁盘，而只是暂时更新到page cache中，同时mark目标page为dirty，当内核主动释放page cache时，才将更新写入到磁盘（主动调用sync时，也会更新到磁盘）。
