|  主机  |      地址       |
| :----: | :-------------: |
| master | 192.168.186.101 |
| slave1 | 192.168.186.102 |
| slave2 | 192.168.186.103 |



hadoop集群搭建

- 配置静态IP
- 关闭防火墙
- 修改主机名
- 配置免密登录
- 集群时间同步



#修改主机名

```powershell
vi /etc/hostname
```

#添加地址主机映射

```text
vi /etc/hosts
```

#关闭防火墙

`systemctl stop firewalld`

`systemctl disable firewalld.service`

#创建 hadoop 用户，并修改 hadoop 用户的密码

```text
#创建hadoop用户
sudo useradd hadoop 
#设置hadoop用户密码
sudo passwd hadoop 
配置hadoop用户具有root权限
vi /etc/sudoers
#找到文件中Allow root to run any commands anywhere 这一行
#添加 hadoop ALL=(ALL:ALL) NOPASSWD:ALL
#若root用户也无法修改该文件，则使用 visudo -f /etc/sudoers
```

#安装必要环境

```
yum install -y epel-release
yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static
```

#配置ssh免密登录

```
ssh-keygen -t rsa #连续回车
cd /home/hadoop/.ssh 

ssh-copy-id master   ##执行这些命令，将公钥拷贝到需要免密登录的节点上
ssh-copy-id slave1
ssh-copy-id slave2

#执行ssh hadoop01、ssh hadoop02 、ssh hadoop03 验证免密登录是否生效
ssh master
ssh slave1
ssh slave2
```



**A. 修改workers文件**

该文件内容可以指定某几个节点作为数据节点，默认为localhost，我们将其删除并修改为slave1和slave2.当然也可以将master加进去，让master节点既做名称节点，也做数据节点



**B.修改core-site.xml文件**

```
<configuration>
	        <property>
	                <name>fs.defaultFS</name>
	                <value>hdfs://hadoopMaster:9000</value>
	        </property>
	        <property>
	                <name>hadoop.tmp.dir</name>
	                <value>file:/usr/local/hadoop/tmp</value>
	        </property>
	</configuration>
```

fs.defaultFS：指定namenode的hdfs协议的文件系统通信地址，可以指定一个主机+端口
hadoop.tmp.dir：hadoop集群在工作时存储的一些临时文件存放的目录

**C.修改hdfs-site.xml文件**

```
	<configuration>
	        <property>
	                <name>dfs.namenode.secondary.http-address</name>
	                <value>slave1:50090</value>
	        </property>
	        <property>
	                <name>dfs.replication</name>
	                <value>3</value>
	        </property>
	        <property>
	                <name>dfs.namenode.name.dir</name>
	                <value>file:/usr/local/hadoop/tmp/dfs/name</value>
	        </property>
	        <property>
	                <name>dfs.datanode.data.dir</name>
	                <value>file:/usr/local/hadoop/tmp/dfs/data</value>
	        </property>
	</configuration>
```

dfs.namenode.name.dir：namenode数据的存放位置，元数据存放位置
dfs.datanode.data.dir：datanode数据的存放位置，block块存放的位置
dfs.repliction：hdfs的副本数设置，默认为3
dfs.secondary.http.address：secondarynamenode运行节点的信息，应该和namenode存放在不同节点

**D.修改mapred-site.xml文件**

```
<configuration>
	        <property>
	                <name>mapreduce.framework.name</name>
	                <value>yarn</value>
	        </property>
	        <property>
	                <name>mapreduce.jobhistory.address</name>
	                <value>hadoopMaster:10020</value>
	        </property>
	        <property>
	                <name>mapreduce.jobhistory.webapp.address</name>
	                <value>hadoopMaster:19888</value>
	        </property>
	        <property>
	                <name>yarn.app.mapreduce.am.env</name>
	                <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
	        </property>
	        <property>
	                <name>mapreduce.map.env</name>
	                <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
	        </property>
	        <property>
	                <name>mapreduce.reduce.env</name>
	                <value>HADOOP_MAPRED_HOME=/usr/local/hadoop</value>
	        </property> 
	</configuration>
```

mapreduce.framework.name：指定mapreduce框架为yarn方式
mapreduce.jobhistory.address：指定历史服务器的地址和端口
mapreduce.jobhistory.webapp.address：查看历史服务器已经运行完的Mapreduce作业记录的web地址，需要启动该服务才行

**E.修改yarn-site.xml文件**

```
<!-- 设置 YARN 集群主角色运行机器位置 -->
<property>
    <name>yarn.resourcemanager.hostname</name>
    <value>node1</value>
</property>

<property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
</property>

<!-- 是否对容器实施物理内存限制 -->
<property>
    <name>yarn.nodemanager.pmem-check-enabled</name>
    <value>false</value>
</property>

<!-- 是否对容器实施虚拟内存限制 -->
<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>

<!-- 开启日志聚集-->
<property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>

<!-- 设置 yarn 历史服务器地址 -->
<property>
    <name>yarn.log.server.url</name>
    <value>http://node1:19888/jobhistory/logs</value>
</property>
```



## 启动集群

Hadoop 提供了两种启动方式：

- 使用命令逐个启动进程 – 每台机器都要手动执行命令，可精准控制每个进程的启动。
- 使用脚本一键启动 – 前提是要配置好机器之间的 SSH 免密登录和 `etc/hadoop/workers` 文件。

**逐个启动进程的命令**

```
# HDFS 集群
$HADOOP_HOME/bin/hdfs --daemon start namenode | datanode | secondarynamenode

# YARN 集群
$HADOOP_HOME/bin/yarn --daemon start resourcemanager | nodemanager | proxyserver
```

**启动集群的脚本**：

HDFS 集群 – $HADOOP_HOME/sbin/start-dfs.sh，一键启动 HDFS 集群的所有进程。
YARN 集群 – $HADOOP_HOME/sbin/start-yarn.sh，一键启动 YARN 集群的所有进程
Hadoop 集群 – $HADOOP_HOME/sbin/start-all.sh，一键启动 HDFS 集群和 YARN 集群的所有进程。



1、格式化文件系统

启动集群之前，需要对 HDFS 进行格式化（仅在 master机器执行）。

```
hdfs namenode -format
```

2、启动 HDFS 集群

```
start-dfs.sh
```

3、启动 YARN 集群

```
start-yarn.sh
```



## 停止集群

**逐个终止进程的命令**

```
# HDFS 集群
$HADOOP_HOME/bin/hdfs --daemon stop namenode | datanode | secondarynamenode

# YARN 集群
$HADOOP_HOME/bin/yarn --daemon stop resourcemanager | nodemanager | proxyserver
```

停止集群的脚本：

HDFS 集群 – $HADOOP_HOME/sbin/stop-dfs.sh，一键终止 HDFS 集群的所有进程。
YARN 集群 – $HADOOP_HOME/sbin/stop-yarn.sh，一键终止 YARN 集群的所有进程
Hadoop 集群 – $HADOOP_HOME/sbin/stop-all.sh，一键终止 HDFS 集群和 YARN 集群的所有进程。

使用 `stop-all.sh` 脚本，一次性停止 Hadoop 的所有进程



集群管理页面

HDFS：http://192.168.186.101:9870/dfshealth.html#tab-overview

YARN：http://192.168.186.101:8088/cluster