# 下载kafka

下载地址：[**https://dlcdn.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz**](https://dlcdn.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz)

官网地址：https://kafka.apache.org/

文档地址：https://kafka.apache.org/documentation/#design

```
$ tar -xzf kafka_2.13-3.3.1.tgz
$ cd kafka_2.13-3.3.1
```

# 必要环境

- java 1.8 +

- ##### Kafka with KRaft   或  Kafka with ZooKeeper

```
----------- Kafka with ZooKeeper （后续会被代替） ------------

# Start the ZooKeeper service
$ bin/zookeeper-server-start.sh config/zookeeper.properties

# Start the Kafka broker service
$ bin/kafka-server-start.sh config/server.properties

-------------------------------------------------------------


------------- 推荐 Kafka with KRaft --------------------------
# Generate a Cluster UUID
$ KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"

# Format Log Directories
$ bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties

# Start the Kafka Server
$ bin/kafka-server-start.sh config/kraft/server.properties

```



# 命令使用kafka

1. 创建topic来存储事件

   Kafka是一个分布式的事件流平台，允许您在多台机器上读取、写入、存储和处理事件(在文档中也称为记录或消息)。

   事件示例包括支付交易、移动电话的地理位置更新、运输订单、物联网设备或医疗设备的传感器测量等等。这些事件被组织并存储在主题中。非常简单，主题类似于文件系统中的文件夹，事件就是文件夹中的文件。

   因此，在编写第一个事件之前，必须创建一个主题。

   ```
   #创建 topic
   $ bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092
   
   #查看 topic
   $ bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092
   ```

   

2. 写一些事件到topic

   ```
   $ bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092
   This is my first event
   This is my second event
   
   #You can stop the producer client with Ctrl-C at any time.
   ```

   

3. 从topic读取事件

   ```
   $ bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092
   
   #You can stop the consumer client with Ctrl-C at any time.
   ```

   

4. 使用kafka connect将数据导入/导出为事件流

   使用简单的连接器来运行Kafka Connect，这些连接器可以将数据从文件导入到Kafka主题，并将数据从Kafka主题导出到文件

   首先，确保将connect-file-3.3.1.jar添加到插件中。Connect工作者配置中的path属性。

   编辑config/connect-standalone。属性文件，添加或更改插件。路径配置属性匹配如下，并保存文件:

   ```
   > echo "plugin.path=libs/connect-file-3.3.1.jar"
   
   > echo -e "foo\nbar" > test.txt
   
   #windows
   > echo foo> test.txt
   > echo bar>> test.txt
   
   > bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
   ```

   

5. 用kafka流处理你的事件

6. 终止kafka环境

   使用Ctrl-C停止生产者和消费者客户机(如果还没有这样做的话)。
   用Ctrl-C停止Kafka代理。
   最后，如果遵循了Kafka with ZooKeeper部分，请使用Ctrl-C停止ZooKeeper服务器。
   如果你还想删除你的本地Kafka环境的任何数据，包括你在这个过程中创建的任何事件，运行命令:

   ```
   $ rm -rf /tmp/kafka-logs /tmp/zookeeper /tmp/kraft-combined-logs
   ```

   